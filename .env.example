# 应用配置
APP_ENV=development
APP_NAME=content-crawler
APP_VERSION=0.1.0
DEBUG=true

# 服务器配置
HOST=0.0.0.0
PORT=8000
WORKERS=4

# 数据库配置
DB_TYPE=sqlite  # sqlite/mysql
DB_HOST=localhost
DB_PORT=5432
DB_NAME=content_crawler
DB_USER=postgres
DB_PASSWORD=your_password
DB_POOL_SIZE=5
DB_POOL_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30

# Redis配置
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
REDIS_POOL_SIZE=10
REDIS_POOL_TIMEOUT=30

# LLM配置
OPENAI_API_KEY=your-api-key
ANTHROPIC_API_KEY=your-api-key
LLM_PROVIDER=openai  # openai/anthropic

# 爬虫配置
MAX_CONCURRENT_TASKS=3
REQUEST_TIMEOUT=30
RETRY_TIMES=3
RETRY_DELAY=5
CRAWLER_MAX_WORKERS=10
CRAWLER_MAX_RETRIES=3
CRAWLER_RETRY_DELAY=1
CRAWLER_MAX_DELAY=10
CRAWLER_TIMEOUT=30
CRAWLER_REQUEST_DELAY=1

# 代理配置
USE_PROXY=false
PROXY_API_URL=
PROXY_API_KEY=
PROXY_ENABLED=false
PROXY_HTTP=http://your-proxy-server:port
PROXY_HTTPS=http://your-proxy-server:port
PROXY_USERNAME=
PROXY_PASSWORD=

# 监控配置
ENABLE_METRICS=true
METRICS_PORT=9090
MONITOR_ENABLED=true
MONITOR_INTERVAL=60
MONITOR_METRICS_PORT=9090
MONITOR_ALERT_WEBHOOK=

# 日志配置
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=logs/app.log
LOG_DIR=logs
LOG_MAX_SIZE=100MB
LOG_BACKUP_COUNT=30
LOG_ROTATION=midnight

# 安全配置
SECRET_KEY=your-secret-key
ACCESS_TOKEN_EXPIRE_MINUTES=30
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080
SECURITY_ENABLED=true
SECURITY_SECRET_KEY=your-secret-key
SECURITY_ALGORITHM=HS256
SECURITY_ACCESS_TOKEN_EXPIRE=86400

# 存储配置
STORAGE_TYPE=local  # local/s3
STORAGE_PATH=storage
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=
AWS_BUCKET=

# 告警配置
ENABLE_ALERTS=true
ALERT_EMAIL=
SMTP_HOST=
SMTP_PORT=
SMTP_USER=
SMTP_PASSWORD=

# 内容配置
CONTENT_MIN_LIKES=100
CONTENT_MIN_COMMENTS=10
CONTENT_MIN_COLLECTS=50
CONTENT_MAX_AGE_DAYS=30
CONTENT_QUALITY_THRESHOLD=0.7

# 缓存配置
CACHE_ENABLED=true
CACHE_TTL=3600
CACHE_MAX_SIZE=1000
CACHE_CLEANUP_INTERVAL=300

# API配置
API_VERSION=v1
API_PREFIX=/api
API_DEBUG=false
API_CORS_ORIGINS=*
API_RATE_LIMIT=100/minute 